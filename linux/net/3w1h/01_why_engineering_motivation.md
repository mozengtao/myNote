# WHY｜工程动机（为什么需要它）

## Linux 网络子系统架构总览

```
LINUX NETWORK SUBSYSTEM ARCHITECTURE OVERVIEW
+=============================================================================+
|                                                                              |
|  USER SPACE                                                                  |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │  Applications: wget, curl, nginx, mysql, ssh, ...                       │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                              │                                               |
|                    ══════════╪══════════  System Call Boundary               |
|                              ▼                                               |
|  KERNEL SPACE                                                                |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                      SOCKET LAYER                                        │ |
|  │  ┌──────────────────────────────────────────────────────────────────┐  │ |
|  │  │  struct socket / struct sock                                      │  │ |
|  │  │  tcp_sendmsg() / tcp_recvmsg() / tcp_poll()                       │  │ |
|  │  │  socket options, buffer management                                │  │ |
|  │  └──────────────────────────────────────────────────────────────────┘  │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                              │                                               |
|                              ▼                                               |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                    TRANSPORT LAYER                                       │ |
|  │  ┌───────────────────┐  ┌───────────────────┐  ┌──────────────────┐    │ |
|  │  │        TCP        │  │        UDP        │  │      SCTP        │    │ |
|  │  │  tcp_v4_connect() │  │  udp_sendmsg()    │  │                  │    │ |
|  │  │  tcp_close()      │  │  udp_recvmsg()    │  │                  │    │ |
|  │  │  tcp_set_state()  │  │                   │  │                  │    │ |
|  │  └───────────────────┘  └───────────────────┘  └──────────────────┘    │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                              │                                               |
|                              ▼                                               |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                     NETWORK LAYER                                        │ |
|  │  ┌───────────────────┐  ┌───────────────────┐  ┌──────────────────┐    │ |
|  │  │       IPv4        │  │       IPv6        │  │       ARP        │    │ |
|  │  │  ip_rcv()         │  │  ipv6_rcv()       │  │  arp_rcv()       │    │ |
|  │  │  ip_output()      │  │  ip6_output()     │  │  arp_send()      │    │ |
|  │  └───────────────────┘  └───────────────────┘  └──────────────────┘    │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                              │                                               |
|                              ▼                                               |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                     DEVICE LAYER                                         │ |
|  │  ┌──────────────────────────────────────────────────────────────────┐  │ |
|  │  │  struct net_device / struct net_device_ops                        │  │ |
|  │  │  netif_receive_skb() / dev_queue_xmit()                           │  │ |
|  │  │  NAPI polling, traffic control, qdisc                             │  │ |
|  │  └──────────────────────────────────────────────────────────────────┘  │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                              │                                               |
|                              ▼                                               |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                     DRIVER LAYER                                         │ |
|  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐  ┌────────────┐  │ |
|  │  │    e1000e    │  │    ixgbe     │  │    virtio    │  │   tun/tap  │  │ |
|  │  └──────────────┘  └──────────────┘  └──────────────┘  └────────────┘  │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                              │                                               |
|                    ══════════╪══════════  Hardware Boundary                  |
|                              ▼                                               |
|  HARDWARE                                                                    |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │  NIC (Network Interface Card)                                           │ |
|  │  DMA, Ring Buffers, Interrupts                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
+=============================================================================+
```

**中文说明：**

Linux 网络子系统采用严格的分层架构：
- **Socket 层**：提供用户空间 API，管理连接状态和缓冲区
- **传输层**：实现 TCP/UDP/SCTP 等协议，处理可靠传输、拥塞控制
- **网络层**：处理 IP 路由、分片、地址解析
- **设备层**：抽象网络设备，管理数据包队列和流量控制
- **驱动层**：直接与硬件交互，处理 DMA 和中断

---

## 1. 网络子系统解决的真实工程问题

```
ENGINEERING PROBLEMS SOLVED BY NETWORK SUBSYSTEM
+=============================================================================+
|                                                                              |
|  PROBLEM 1: HIGH-PERFORMANCE DATA TRANSFER (高性能数据传输)                  |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                                                                          │ |
|  │  Without subsystem:                                                      │ |
|  │  ┌──────────┐    copy    ┌──────────┐    copy    ┌──────────┐          │ |
|  │  │   App    │ ────────► │  Kernel  │ ────────► │   NIC    │          │ |
|  │  │  Buffer  │           │  Buffer  │           │  Buffer  │          │ |
|  │  └──────────┘           └──────────┘           └──────────┘          │ |
|  │  每个数据包多次拷贝，CPU 开销巨大                                       │ |
|  │                                                                          │ |
|  │  With subsystem (sk_buff + zero-copy):                                   │ |
|  │  ┌──────────┐            ┌──────────────────────────────────┐          │ |
|  │  │   App    │            │         sk_buff (shared)          │          │ |
|  │  │  sendfile│ ─────────► │  data pointer + metadata          │          │ |
|  │  └──────────┘            │  → DMA directly to NIC            │          │ |
|  │                          └──────────────────────────────────┘          │ |
|  │  零拷贝或最小拷贝，大幅提升吞吐量                                       │ |
|  │                                                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
|  PROBLEM 2: MULTI-PROTOCOL SUPPORT (多协议支持)                              |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                                                                          │ |
|  │  必须同时支持：                                                          │ |
|  │  • TCP (可靠、面向连接、流量控制、拥塞控制)                             │ |
|  │  • UDP (不可靠、无连接、低延迟)                                         │ |
|  │  • SCTP (多流、多宿主)                                                  │ |
|  │  • Raw IP (直接 IP 数据包)                                              │ |
|  │  • ICMP (控制消息)                                                      │ |
|  │  • IPv4 / IPv6                                                          │ |
|  │                                                                          │ |
|  │  解决方案：协议栈模块化，每个协议独立实现                                │ |
|  │                                                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
|  PROBLEM 3: CONCURRENT PACKET PROCESSING (并发数据包处理)                    |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                                                                          │ |
|  │  Modern servers:                                                         │ |
|  │  • 64+ CPU cores                                                         │ |
|  │  • 100+ Gbps network                                                     │ |
|  │  • Millions of packets per second                                        │ |
|  │                                                                          │ |
|  │  挑战：                                                                  │ |
|  │  • 多 CPU 同时处理不同连接                                              │ |
|  │  • 避免锁竞争成为瓶颈                                                    │ |
|  │  • 保持数据一致性                                                        │ |
|  │                                                                          │ |
|  │  解决方案：                                                              │ |
|  │  • RCU (Read-Copy-Update) 无锁读                                        │ |
|  │  • Per-CPU 数据结构                                                     │ |
|  │  • NAPI 批量处理减少中断                                                │ |
|  │  • 连接级别的锁（而非全局锁）                                           │ |
|  │                                                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
|  PROBLEM 4: DEVICE ABSTRACTION (设备抽象)                                    |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                                                                          │ |
|  │  网卡种类繁多：                                                          │ |
|  │  • Intel e1000, ixgbe, i40e                                             │ |
|  │  • Broadcom bnx2, tg3                                                   │ |
|  │  • Mellanox mlx4, mlx5                                                  │ |
|  │  • Virtual: virtio, veth, tun/tap                                       │ |
|  │  • Wireless: iwlwifi, ath9k                                             │ |
|  │                                                                          │ |
|  │  Without abstraction:                                                    │ |
|  │  每个协议栈都要为每种网卡写适配代码                                      │ |
|  │  N protocols × M drivers = N×M implementations                          │ |
|  │                                                                          │ |
|  │  With net_device abstraction:                                            │ |
|  │  协议栈只和 net_device 交互                                              │ |
|  │  N protocols + M drivers = N+M implementations                          │ |
|  │                                                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
+=============================================================================+
```

**中文说明：**

网络子系统解决的四大核心问题：
1. **高性能传输**：通过 sk_buff 共享和零拷贝技术减少数据拷贝
2. **多协议支持**：模块化协议栈，TCP/UDP/SCTP 等独立实现
3. **并发处理**：RCU、Per-CPU 结构、NAPI 批量处理
4. **设备抽象**：net_device 统一接口，解耦协议栈和驱动

---

## 2. 如果没有网络子系统，系统会如何失败

```
FAILURE MODES WITHOUT NETWORK SUBSYSTEM
+=============================================================================+
|                                                                              |
|  FAILURE 1: DRIVER CHAOS (驱动混乱)                                          |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                                                                          │ |
|  │  Without unified interface:                                              │ |
|  │                                                                          │ |
|  │  ┌─────────┐     ┌─────────┐     ┌─────────┐                            │ |
|  │  │   TCP   │     │   TCP   │     │   TCP   │                            │ |
|  │  │ for e1000│     │for ixgbe│     │for virtio│                            │ |
|  │  └────┬────┘     └────┬────┘     └────┬────┘                            │ |
|  │       │               │               │                                  │ |
|  │  ┌────▼────┐     ┌────▼────┐     ┌────▼────┐                            │ |
|  │  │  e1000  │     │  ixgbe  │     │  virtio │                            │ |
|  │  └─────────┘     └─────────┘     └─────────┘                            │ |
|  │                                                                          │ |
|  │  每换一种网卡就要重写协议栈                                              │ |
|  │  Bug 在每个组合中都可能不同                                              │ |
|  │  测试矩阵爆炸                                                            │ |
|  │                                                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
|  FAILURE 2: PERFORMANCE COLLAPSE (性能崩溃)                                  |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                                                                          │ |
|  │  Without NAPI and batching:                                              │ |
|  │                                                                          │ |
|  │  每个数据包都触发硬中断：                                                │ |
|  │  Packet 1 → IRQ → context switch → process → return                     │ |
|  │  Packet 2 → IRQ → context switch → process → return                     │ |
|  │  Packet 3 → IRQ → context switch → process → return                     │ |
|  │  ...                                                                     │ |
|  │                                                                          │ |
|  │  10Gbps ≈ 14.8M packets/sec                                             │ |
|  │  每个中断开销 ~1-2μs                                                    │ |
|  │  = 100% CPU 时间花在中断处理上！                                         │ |
|  │                                                                          │ |
|  │  With NAPI:                                                              │ |
|  │  Packets 1-64 → single poll → batch process → return                    │ |
|  │  中断只用于唤醒轮询，大幅降低开销                                        │ |
|  │                                                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
|  FAILURE 3: STATE MANAGEMENT NIGHTMARE (状态管理噩梦)                        |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                                                                          │ |
|  │  TCP connection lifecycle (from tcp.c):                                  │ |
|  │                                                                          │ |
|  │  TCP_CLOSE → TCP_SYN_SENT → TCP_SYN_RECV → TCP_ESTABLISHED              │ |
|  │      ↑                                           │                       │ |
|  │      │     ┌─────────────────────────────────────┘                       │ |
|  │      │     ▼                                                             │ |
|  │      ├── TCP_FIN_WAIT1 → TCP_FIN_WAIT2 → TCP_TIME_WAIT                   │ |
|  │      │                         │                   │                     │ |
|  │      │                         ▼                   ▼                     │ |
|  │      ├── TCP_CLOSE_WAIT → TCP_LAST_ACK ───────────┘                      │ |
|  │      │                         │                                         │ |
|  │      └─────────────────────────┘                                         │ |
|  │                                                                          │ |
|  │  Without proper state machine:                                           │ |
|  │  • 连接泄漏（未正确关闭）                                                │ |
|  │  • 资源耗尽（TIME_WAIT 积累）                                            │ |
|  │  • 数据丢失（状态不一致）                                                │ |
|  │  • 安全漏洞（状态混淆攻击）                                              │ |
|  │                                                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
|  FAILURE 4: CONCURRENCY BUGS (并发 Bug)                                      |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                                                                          │ |
|  │  Without proper locking (from tcp.c):                                    │ |
|  │                                                                          │ |
|  │  CPU 0                          CPU 1                                    │ |
|  │  ─────                          ─────                                    │ |
|  │  tcp_recvmsg()                  tcp_close()                              │ |
|  │      │                              │                                    │ |
|  │      ▼                              ▼                                    │ |
|  │  read sk->sk_state              sk->sk_state = TCP_CLOSE                 │ |
|  │      │                              │                                    │ |
|  │      ▼                              ▼                                    │ |
|  │  access receive queue           free receive queue                       │ |
|  │      │                                                                   │ |
|  │      ▼                                                                   │ |
|  │  USE AFTER FREE! 💥                                                      │ |
|  │                                                                          │ |
|  │  解决方案 (tcp.c 中的实现):                                               │ |
|  │  lock_sock(sk);     // 获取 socket 锁                                    │ |
|  │  // critical section                                                     │ |
|  │  release_sock(sk);  // 释放 socket 锁                                    │ |
|  │                                                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
+=============================================================================+
```

**中文说明：**

没有统一的网络子系统会导致：
1. **驱动混乱**：每种网卡都需要独立的协议实现，维护成本指数级增长
2. **性能崩溃**：没有 NAPI 批量处理，每包中断导致 CPU 耗尽
3. **状态管理噩梦**：TCP 11 个状态如果没有统一管理，会导致连接泄漏和安全漏洞
4. **并发 Bug**：多 CPU 同时操作同一连接，没有锁保护会导致内存错误

---

## 3. 网络子系统主要应对的复杂度类型

```
COMPLEXITY TYPES ADDRESSED BY NETWORK SUBSYSTEM
+=============================================================================+
|                                                                              |
|  ┌─────────────────────────────────────────────────────────────────────────┐|
|  │                                                                          ||
|  │  PERFORMANCE COMPLEXITY (性能复杂度)                       Priority: ★★★★★||
|  │  ────────────────────────────────────                                    ||
|  │  • 零拷贝：sendfile(), splice(), MSG_ZEROCOPY                           ||
|  │  • 批量处理：NAPI, GRO (Generic Receive Offload)                        ||
|  │  • 缓存优化：sk_buff 头部对齐到 cache line                              ||
|  │  • 路径优化：TCP fast path (tcp.c 中体现)                               ||
|  │                                                                          ||
|  │  tcp.c 中的例子:                                                         ||
|  │  ```c                                                                    ||
|  │  // TCP 快速路径检查                                                     ||
|  │  if (tp->rcv_nxt - tp->copied_seq >= target)                            ||
|  │      mask |= POLLIN | POLLRDNORM;  // 可以立即读取                      ||
|  │  ```                                                                     ||
|  │                                                                          ||
|  └─────────────────────────────────────────────────────────────────────────┘|
|                                                                              |
|  ┌─────────────────────────────────────────────────────────────────────────┐|
|  │                                                                          ||
|  │  CONCURRENCY COMPLEXITY (并发复杂度)                       Priority: ★★★★★||
|  │  ───────────────────────────────────                                     ||
|  │  • Socket 锁：lock_sock() / release_sock()                              ||
|  │  • BH 锁：bh_lock_sock() / bh_unlock_sock()                             ||
|  │  • RCU：网络命名空间、路由表的无锁读                                     ||
|  │  • 引用计数：sock_hold() / sock_put()                                   ||
|  │                                                                          ||
|  │  tcp.c 中的例子:                                                         ||
|  │  ```c                                                                    ||
|  │  void tcp_close(struct sock *sk, long timeout)                          ||
|  │  {                                                                       ||
|  │      lock_sock(sk);               // 用户上下文锁                        ||
|  │      // ... 处理关闭逻辑 ...                                             ||
|  │      release_sock(sk);                                                   ||
|  │                                                                          ||
|  │      local_bh_disable();          // 禁止软中断                          ||
|  │      bh_lock_sock(sk);            // BH 上下文锁                         ||
|  │      // ... BH 上下文处理 ...                                            ||
|  │      bh_unlock_sock(sk);                                                 ||
|  │      local_bh_enable();                                                  ||
|  │  }                                                                       ||
|  │  ```                                                                     ||
|  │                                                                          ||
|  └─────────────────────────────────────────────────────────────────────────┘|
|                                                                              |
|  ┌─────────────────────────────────────────────────────────────────────────┐|
|  │                                                                          ||
|  │  CORRECTNESS COMPLEXITY (正确性复杂度)                     Priority: ★★★★☆||
|  │  ──────────────────────────────────                                      ||
|  │  • TCP 状态机严格按 RFC 793 实现                                         ||
|  │  • 序列号管理、ACK 处理、重传逻辑                                        ||
|  │  • 拥塞控制算法 (Reno, Cubic, BBR)                                      ||
|  │                                                                          ||
|  │  tcp.c 中的状态转换表:                                                   ||
|  │  ```c                                                                    ||
|  │  static const unsigned char new_state[16] = {                            ||
|  │    /* TCP_ESTABLISHED */ TCP_FIN_WAIT1 | TCP_ACTION_FIN,                 ||
|  │    /* TCP_SYN_SENT    */ TCP_CLOSE,                                      ||
|  │    /* TCP_SYN_RECV    */ TCP_FIN_WAIT1 | TCP_ACTION_FIN,                 ||
|  │    /* TCP_FIN_WAIT1   */ TCP_FIN_WAIT1,                                  ||
|  │    // ...                                                                ||
|  │  };                                                                      ||
|  │  ```                                                                     ||
|  │                                                                          ||
|  └─────────────────────────────────────────────────────────────────────────┘|
|                                                                              |
|  ┌─────────────────────────────────────────────────────────────────────────┐|
|  │                                                                          ||
|  │  EXTENSIBILITY COMPLEXITY (可扩展复杂度)                   Priority: ★★★★☆||
|  │  ─────────────────────────────────────                                   ||
|  │  • 新协议可以注册到协议栈                                                ||
|  │  • 新网卡驱动可以注册到设备层                                            ||
|  │  • 拥塞控制算法可插拔                                                    ||
|  │  • Netfilter hook 点                                                     ||
|  │                                                                          ||
|  │  tcp.c 中的扩展点:                                                       ||
|  │  ```c                                                                    ||
|  │  // 拥塞控制算法注册                                                     ||
|  │  tcp_register_congestion_control(&tcp_reno);                             ||
|  │                                                                          ||
|  │  // 协议特定操作表                                                       ||
|  │  icsk->icsk_af_ops->setsockopt(sk, level, optname, ...);                 ||
|  │  ```                                                                     ||
|  │                                                                          ||
|  └─────────────────────────────────────────────────────────────────────────┘|
|                                                                              |
|  ┌─────────────────────────────────────────────────────────────────────────┐|
|  │                                                                          ||
|  │  MAINTAINABILITY COMPLEXITY (可维护复杂度)                 Priority: ★★★☆☆||
|  │  ───────────────────────────────────────                                 ||
|  │  • 代码分层清晰                                                          ||
|  │  • 抽象接口稳定                                                          ||
|  │  • 调试信息丰富                                                          ||
|  │                                                                          ||
|  │  tcp.c 中的调试支持:                                                     ||
|  │  ```c                                                                    ||
|  │  #ifdef STATE_TRACE                                                      ||
|  │  SOCK_DEBUG(sk, "TCP sk=%p, State %s -> %s\n",                          ||
|  │             sk, statename[oldstate], statename[state]);                  ||
|  │  #endif                                                                  ||
|  │  ```                                                                     ||
|  │                                                                          ||
|  └─────────────────────────────────────────────────────────────────────────┘|
|                                                                              |
+=============================================================================+
```

**中文说明：**

网络子系统处理的复杂度按优先级排序：
1. **性能复杂度**（★★★★★）：零拷贝、批量处理、快速路径优化
2. **并发复杂度**（★★★★★）：多层锁机制、RCU、引用计数
3. **正确性复杂度**（★★★★☆）：TCP 状态机、序列号管理、拥塞控制
4. **可扩展复杂度**（★★★★☆）：协议/驱动/算法的插件机制
5. **可维护复杂度**（★★★☆☆）：分层设计、调试支持

---

## 4. 工程背景与历史条件

```
HISTORICAL CONTEXT OF LINUX NETWORK SUBSYSTEM
+=============================================================================+
|                                                                              |
|  TIMELINE                                                                    |
|  ────────                                                                    |
|                                                                              |
|  1991 ─┬─ Linux 0.01: 无网络支持                                             |
|        │                                                                     |
|  1992 ─┼─ Linux 0.96: 初步网络支持，基于 NET-1                               |
|        │  • 简单的 socket 层                                                 |
|        │  • 基本 TCP/IP 实现                                                 |
|        │                                                                     |
|  1994 ─┼─ Linux 1.0: NET-2 重写                                              |
|        │  • 模块化网络栈                                                     |
|        │  • sk_buff 数据结构引入                                             |
|        │                                                                     |
|  1996 ─┼─ Linux 2.0: SMP 支持                                                |
|        │  • 大内核锁 (BKL)                                                   |
|        │  • 初步并发支持                                                     |
|        │                                                                     |
|  1999 ─┼─ Linux 2.2: 网络性能优化                                            |
|        │  • socket hash 表优化                                               |
|        │  • 更好的内存管理                                                   |
|        │                                                                     |
|  2001 ─┼─ Linux 2.4: Netfilter/iptables                                      |
|        │  • 灵活的包过滤框架                                                 |
|        │  • 连接跟踪                                                         |
|        │                                                                     |
|  2003 ─┼─ Linux 2.6: NAPI 引入                                               |
|        │  • 解决中断风暴问题                                                 |
|        │  • 高速网络支持                                                     |
|        │                                                                     |
|  2005 ─┼─ RCU 广泛应用                                                       |
|        │  • 无锁读优化                                                       |
|        │  • 路由表等关键结构                                                 |
|        │                                                                     |
|  2008 ─┼─ 网络命名空间                                                       |
|        │  • 容器化支持                                                       |
|        │  • 网络隔离                                                         |
|        │                                                                     |
|  2011 ─┼─ Linux 3.0-3.2 (当前版本)                                           |
|        │  • 成熟的多核支持                                                   |
|        │  • 完善的拥塞控制                                                   |
|        │  • 丰富的 socket 选项                                               |
|        │                                                                     |
|  ─────────────────────────────────────────────────────────────────────────   |
|                                                                              |
|  KEY DRIVERS (关键驱动因素):                                                 |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                                                                          │ |
|  │  1. 网络速度增长:                                                        │ |
|  │     10Mbps → 100Mbps → 1Gbps → 10Gbps → 100Gbps                         │ |
|  │     每次提升都要求软件栈优化                                             │ |
|  │                                                                          │ |
|  │  2. 多核 CPU 普及:                                                       │ |
|  │     1 core → 2 cores → 4 cores → 8+ cores                               │ |
|  │     必须充分利用并发能力                                                 │ |
|  │                                                                          │ |
|  │  3. 服务器负载增长:                                                      │ |
|  │     100 connections → 10K → 100K → 1M+ (C10K, C10M 问题)                 │ |
|  │     需要高效的连接管理                                                   │ |
|  │                                                                          │ |
|  │  4. 虚拟化和容器化:                                                      │ |
|  │     物理机 → VM → Container → Microservices                              │ |
|  │     需要网络命名空间和虚拟网络设备                                       │ |
|  │                                                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
+=============================================================================+
```

**中文说明：**

Linux 网络子系统的演进受以下因素驱动：
1. **网络带宽增长**：从 10Mbps 到 100Gbps，软件栈必须跟上硬件发展
2. **多核 CPU 普及**：从单核到多核，需要充分利用并发能力
3. **连接数爆发**：C10K 到 C10M 问题，需要高效的连接管理
4. **虚拟化需求**：容器和微服务需要网络隔离和虚拟设备

Linux 3.2 版本处于成熟期，具备：
- 完善的 NAPI 机制
- 成熟的 RCU 无锁优化
- 丰富的 socket 选项（如 `TCP_NODELAY`, `TCP_CORK`, `TCP_CONGESTION`）
- 可插拔的拥塞控制算法
