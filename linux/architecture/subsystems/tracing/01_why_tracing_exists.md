# WHY｜为什么需要追踪

## 1. 日志的局限性

```
LIMITS OF LOGGING
+=============================================================================+
|                                                                              |
|  TRADITIONAL LOGGING                                                         |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                                                                          │ |
|  │  ┌─────────────────────────────────────────────────────────────────┐    │ |
|  │  │                                                                  │    │ |
|  │  │  Code with logs:                                                 │    │ |
|  │  │  ┌────────────────────────────────────────────────────────────┐ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  void process_request(Request *req) {                       │ │    │ |
|  │  │  │      LOG_INFO("Processing request %d", req->id);            │ │    │ |
|  │  │  │      validate(req);                                         │ │    │ |
|  │  │  │      LOG_DEBUG("Validation passed");                        │ │    │ |
|  │  │  │      result = execute(req);                                 │ │    │ |
|  │  │  │      if (result < 0)                                        │ │    │ |
|  │  │  │          LOG_ERROR("Execution failed: %d", result);         │ │    │ |
|  │  │  │      LOG_INFO("Request %d completed", req->id);             │ │    │ |
|  │  │  │  }                                                          │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  └────────────────────────────────────────────────────────────┘ │    │ |
|  │  │                                                                  │    │ |
|  │  │  Problems with this approach:                                    │    │ |
|  │  │                                                                  │    │ |
|  │  └─────────────────────────────────────────────────────────────────┘    │ |
|  │                                                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
|  PROBLEM 1: FIXED AT COMPILE TIME                                            |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                                                                          │ |
|  │  ┌─────────────────────────────────────────────────────────────────┐    │ |
|  │  │                                                                  │    │ |
|  │  │  You ONLY see what was PREDICTED:                                │    │ |
|  │  │                                                                  │    │ |
|  │  │  Production Issue:                                               │    │ |
|  │  │  "Why is this request taking 500ms?"                             │    │ |
|  │  │                                                                  │    │ |
|  │  │  Logs show:                                                      │    │ |
|  │  │  ┌────────────────────────────────────────────────────────────┐ │    │ |
|  │  │  │  10:00:00.000  Processing request 12345                     │ │    │ |
|  │  │  │  10:00:00.500  Request 12345 completed                      │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  WHERE did the 500ms go? No visibility!                     │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  └────────────────────────────────────────────────────────────┘ │    │ |
|  │  │                                                                  │    │ |
|  │  │  To find out, you need to:                                       │    │ |
|  │  │  1. Add more logs                                                │    │ |
|  │  │  2. Recompile                                                    │    │ |
|  │  │  3. Redeploy                                                     │    │ |
|  │  │  4. Wait for issue to recur                                      │    │ |
|  │  │  5. Hope you added logs in the right place                       │    │ |
|  │  │                                                                  │    │ |
|  │  │  Tracing: Add instrumentation DYNAMICALLY, no rebuild!           │    │ |
|  │  │                                                                  │    │ |
|  │  └─────────────────────────────────────────────────────────────────┘    │ |
|  │                                                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
|  PROBLEM 2: ALL OR NOTHING                                                   |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                                                                          │ |
|  │  ┌─────────────────────────────────────────────────────────────────┐    │ |
|  │  │                                                                  │    │ |
|  │  │  Log levels: DEBUG, INFO, WARN, ERROR                            │    │ |
|  │  │                                                                  │    │ |
|  │  │  In production:                                                  │    │ |
|  │  │  ┌────────────────────────────────────────────────────────────┐ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  log_level = INFO                                           │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  → All DEBUG logs disabled (might have the answer!)         │ │    │ |
|  │  │  │  → If enabled, LOG STORM! (100K logs/second)                │ │    │ |
|  │  │  │  → I/O becomes bottleneck                                   │ │    │ |
|  │  │  │  → Can't enable selectively for just ONE request            │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  └────────────────────────────────────────────────────────────┘ │    │ |
|  │  │                                                                  │    │ |
|  │  │  Tracing: Enable for specific subsystems, requests, or PIDs      │    │ |
|  │  │                                                                  │    │ |
|  │  └─────────────────────────────────────────────────────────────────┘    │ |
|  │                                                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
|  PROBLEM 3: HIGH OVERHEAD                                                    |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                                                                          │ |
|  │  ┌─────────────────────────────────────────────────────────────────┐    │ |
|  │  │                                                                  │    │ |
|  │  │  Every log call:                                                 │    │ |
|  │  │  ┌────────────────────────────────────────────────────────────┐ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  1. Format string processing      ~100 ns                   │ │    │ |
|  │  │  │  2. Memory allocation             ~50 ns                    │ │    │ |
|  │  │  │  3. Lock acquisition              ~20-1000 ns               │ │    │ |
|  │  │  │  4. Write to buffer               ~50 ns                    │ │    │ |
|  │  │  │  5. Maybe syscall to disk         ~1000+ ns                 │ │    │ |
|  │  │  │  ───────────────────────────────────────                    │ │    │ |
|  │  │  │  Total: 200-2000+ ns per log                                │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  At 1M requests/sec with 10 logs each:                      │ │    │ |
|  │  │  │  → 10M log calls/sec                                        │ │    │ |
|  │  │  │  → 2-20+ seconds of CPU time PER SECOND                     │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  └────────────────────────────────────────────────────────────┘ │    │ |
|  │  │                                                                  │    │ |
|  │  │  Tracing (disabled): ~1-5 ns (branch prediction)                 │    │ |
|  │  │  Tracing (enabled):  ~100-500 ns (ring buffer, no I/O)           │    │ |
|  │  │                                                                  │    │ |
|  │  └─────────────────────────────────────────────────────────────────┘    │ |
|  │                                                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
|  PROBLEM 4: NO CORRELATION                                                   |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                                                                          │ |
|  │  ┌─────────────────────────────────────────────────────────────────┐    │ |
|  │  │                                                                  │    │ |
|  │  │  Logs from different components:                                 │    │ |
|  │  │  ┌────────────────────────────────────────────────────────────┐ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  [scheduler] Woke process 1234                              │ │    │ |
|  │  │  │  [disk] Read block 567890                                   │ │    │ |
|  │  │  │  [network] Packet received on eth0                          │ │    │ |
|  │  │  │  [memory] Page fault at 0x7fff1234                          │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  Questions you can't answer:                                │ │    │ |
|  │  │  │  • Which disk read was caused by which process?             │ │    │ |
|  │  │  │  • What triggered this page fault?                          │ │    │ |
|  │  │  │  • What's the end-to-end latency of a request?              │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  └────────────────────────────────────────────────────────────┘ │    │ |
|  │  │                                                                  │    │ |
|  │  │  Tracing: Events have timestamps, PIDs, stack traces             │    │ |
|  │  │           Can reconstruct causality                              │    │ |
|  │  │                                                                  │    │ |
|  │  └─────────────────────────────────────────────────────────────────┘    │ |
|  │                                                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
+=============================================================================+
```

**中文说明：**

**日志的局限性**：

**问题 1：编译时固定**
- 只能看到预测到的内容
- 生产问题："为什么这个请求需要 500ms？"
- 日志只显示开始和结束，看不到 500ms 去哪了
- 要找出原因需要：添加更多日志 → 重新编译 → 重新部署 → 等待问题重现
- 追踪：动态添加检测，无需重建！

**问题 2：全有或全无**
- 日志级别：DEBUG、INFO、WARN、ERROR
- 生产中 log_level = INFO，所有 DEBUG 日志禁用
- 如果启用，日志风暴！（10 万/秒）
- 无法只为一个请求选择性启用
- 追踪：可为特定子系统、请求或 PID 启用

**问题 3：高开销**
- 每次日志调用：200-2000+ ns
- 100 万请求/秒，每个 10 条日志 → 每秒 2-20+ 秒 CPU 时间
- 追踪（禁用）：~1-5 ns（分支预测）
- 追踪（启用）：~100-500 ns（环形缓冲区，无 I/O）

**问题 4：无关联**
- 来自不同组件的日志无法关联
- 追踪：事件有时间戳、PID、堆栈跟踪，可重建因果关系

---

## 2. 生产调试需求

```
PRODUCTION DEBUGGING NEEDS
+=============================================================================+
|                                                                              |
|  THE PRODUCTION REALITY                                                      |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                                                                          │ |
|  │  ┌─────────────────────────────────────────────────────────────────┐    │ |
|  │  │                                                                  │    │ |
|  │  │  Development:          Production:                               │    │ |
|  │  │  ┌──────────────────┐  ┌──────────────────────────────────────┐ │    │ |
|  │  │  │                  │  │                                       │ │    │ |
|  │  │  │  • Can attach    │  │  • Can't stop the server              │ │    │ |
|  │  │  │    debugger      │  │  • Can't attach gdb (security)        │ │    │ |
|  │  │  │                  │  │  • Can't add printk (need reboot)     │ │    │ |
|  │  │  │  • Can reboot    │  │  • Issues are intermittent            │ │    │ |
|  │  │  │    freely        │  │  • Only happens under load            │ │    │ |
|  │  │  │                  │  │  • Affecting customers NOW            │ │    │ |
|  │  │  │  • Reproducible  │  │  • Can't reproduce in dev             │ │    │ |
|  │  │  │    issues        │  │                                       │ │    │ |
|  │  │  │                  │  │                                       │ │    │ |
|  │  │  └──────────────────┘  └──────────────────────────────────────┘ │    │ |
|  │  │                                                                  │    │ |
|  │  └─────────────────────────────────────────────────────────────────┘    │ |
|  │                                                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
|  WHAT PRODUCTION NEEDS                                                       |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                                                                          │ |
|  │  ┌─────────────────────────────────────────────────────────────────┐    │ |
|  │  │                                                                  │    │ |
|  │  │  1. ALWAYS-ON BASELINE                                           │    │ |
|  │  │  ┌────────────────────────────────────────────────────────────┐ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  • Basic metrics always collecting                          │ │    │ |
|  │  │  │  • Minimal overhead (<1% CPU)                               │ │    │ |
|  │  │  │  • Ready when issue occurs                                  │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  Linux: ftrace ring buffer, always running                  │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  └────────────────────────────────────────────────────────────┘ │    │ |
|  │  │                                                                  │    │ |
|  │  │  2. ON-DEMAND DEEP DIVE                                          │    │ |
|  │  │  ┌────────────────────────────────────────────────────────────┐ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  • Enable detailed tracing when needed                      │ │    │ |
|  │  │  │  • No code change, no reboot                                │ │    │ |
|  │  │  │  • Filter by process, syscall, function                     │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  Linux: kprobes, uprobes, tracepoints                       │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  └────────────────────────────────────────────────────────────┘ │    │ |
|  │  │                                                                  │    │ |
|  │  │  3. LOW OVERHEAD                                                 │    │ |
|  │  │  ┌────────────────────────────────────────────────────────────┐ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  • Can't slow down production by 50% to debug               │ │    │ |
|  │  │  │  • Need <5% overhead even when actively tracing             │ │    │ |
|  │  │  │  • Should work on hot paths (scheduler, network)            │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  Linux: Per-CPU buffers, no locks, binary format            │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  └────────────────────────────────────────────────────────────┘ │    │ |
|  │  │                                                                  │    │ |
|  │  │  4. SAFE TO USE                                                  │    │ |
|  │  │  ┌────────────────────────────────────────────────────────────┐ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  • Can't crash production kernel                            │ │    │ |
|  │  │  │  • Can't introduce security holes                           │ │    │ |
|  │  │  │  • Can't cause data loss                                    │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  Linux: BPF verifier, sandboxed execution                   │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  └────────────────────────────────────────────────────────────┘ │    │ |
|  │  │                                                                  │    │ |
|  │  └─────────────────────────────────────────────────────────────────┘    │ |
|  │                                                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
|  REAL-WORLD QUESTIONS TRACING ANSWERS                                        |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                                                                          │ |
|  │  ┌─────────────────────────────────────────────────────────────────┐    │ |
|  │  │                                                                  │    │ |
|  │  │  • Why is process X slow?                                        │    │ |
|  │  │    → function_graph tracer: show call tree with timing           │    │ |
|  │  │                                                                  │    │ |
|  │  │  • Who is writing to this file?                                  │    │ |
|  │  │    → kprobe on vfs_write with stack trace                        │    │ |
|  │  │                                                                  │    │ |
|  │  │  • What syscalls does this process make?                         │    │ |
|  │  │    → strace (ptrace-based) or seccomp trace                      │    │ |
|  │  │                                                                  │    │ |
|  │  │  • Where is memory being allocated?                              │    │ |
|  │  │    → kmalloc tracepoint + stack traces                           │    │ |
|  │  │                                                                  │    │ |
|  │  │  • Why did this process get killed by OOM?                       │    │ |
|  │  │    → oom tracepoints + memory stat history                       │    │ |
|  │  │                                                                  │    │ |
|  │  │  • What's causing network latency spikes?                        │    │ |
|  │  │    → tcp tracepoints + scheduler tracepoints                     │    │ |
|  │  │                                                                  │    │ |
|  │  └─────────────────────────────────────────────────────────────────┘    │ |
|  │                                                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
+=============================================================================+
```

**中文说明：**

**生产调试需求**：

**生产现实**：
- 开发环境：可以附加调试器、可以自由重启、问题可重现
- 生产环境：不能停止服务器、不能附加 gdb、不能添加 printk（需要重启）、问题是间歇性的、只在负载下发生、正在影响客户、无法在开发中重现

**生产需要什么**：

1. **始终在线的基线**：基本指标始终收集，最小开销（<1% CPU）
   - Linux：ftrace 环形缓冲区，始终运行

2. **按需深入**：需要时启用详细追踪，无代码更改，无重启
   - Linux：kprobes、uprobes、tracepoints

3. **低开销**：即使主动追踪也需要 <5% 开销
   - Linux：Per-CPU 缓冲区，无锁，二进制格式

4. **安全使用**：不能崩溃生产内核，不能引入安全漏洞
   - Linux：BPF 验证器，沙箱执行

**追踪回答的真实问题**：
- 为什么进程 X 慢？→ function_graph tracer
- 谁在写这个文件？→ kprobe on vfs_write
- 内存在哪里分配？→ kmalloc tracepoint + 堆栈跟踪
- 什么导致网络延迟尖峰？→ tcp + scheduler tracepoints

---

## 3. 复杂度：低开销

```
COMPLEXITY: LOW OVERHEAD
+=============================================================================+
|                                                                              |
|  THE OVERHEAD CHALLENGE                                                      |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                                                                          │ |
|  │  ┌─────────────────────────────────────────────────────────────────┐    │ |
|  │  │                                                                  │    │ |
|  │  │  Tracing must be usable on:                                      │    │ |
|  │  │                                                                  │    │ |
|  │  │  ┌────────────────────────────────────────────────────────────┐ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  HOT PATHS:                                                 │ │    │ |
|  │  │  │  • Scheduler (context switch): 10K-100K/sec per CPU         │ │    │ |
|  │  │  │  • Network stack:              1M+ packets/sec              │ │    │ |
|  │  │  │  • Block I/O:                  100K+ IOPS                   │ │    │ |
|  │  │  │  • Page faults:                1K-100K/sec                  │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  If tracing adds 1 μs overhead to scheduler:                │ │    │ |
|  │  │  │  → 100K/sec × 1 μs = 100 ms/sec = 10% CPU overhead!         │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  └────────────────────────────────────────────────────────────┘ │    │ |
|  │  │                                                                  │    │ |
|  │  └─────────────────────────────────────────────────────────────────┘    │ |
|  │                                                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
|  LINUX OVERHEAD OPTIMIZATION TECHNIQUES                                      |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                                                                          │ |
|  │  1. STATIC BRANCHES (JUMP LABELS)                                        │ |
|  │  ┌─────────────────────────────────────────────────────────────────┐    │ |
|  │  │                                                                  │    │ |
|  │  │  When tracing DISABLED:                                          │    │ |
|  │  │  ┌────────────────────────────────────────────────────────────┐ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  // Normal if statement: always evaluates condition         │ │    │ |
|  │  │  │  if (tracepoint_enabled)  // branch misprediction possible  │ │    │ |
|  │  │  │      trace_event();                                         │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  // Static branch: NO runtime check when disabled           │ │    │ |
|  │  │  │  if (static_branch_unlikely(&tp_key))                       │ │    │ |
|  │  │  │      trace_event();                                         │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  Compiled to:                                               │ │    │ |
|  │  │  │  0x1000:  nop        ◄── Just a NOP when disabled           │ │    │ |
|  │  │  │  0x1001:  ...next instruction                               │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  When enabled, NOP is patched to JMP:                       │ │    │ |
|  │  │  │  0x1000:  jmp 0x2000 ◄── Jump to tracing code               │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  Cost when disabled: ~0 cycles (no branch)                  │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  └────────────────────────────────────────────────────────────┘ │    │ |
|  │  │                                                                  │    │ |
|  │  └─────────────────────────────────────────────────────────────────┘    │ |
|  │                                                                          │ |
|  │  2. RING BUFFER (PER-CPU)                                                 │ |
|  │  ┌─────────────────────────────────────────────────────────────────┐    │ |
|  │  │                                                                  │    │ |
|  │  │  ┌────────────────────────────────────────────────────────────┐ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  CPU 0              CPU 1              CPU 2               │ │    │ |
|  │  │  │  ┌──────────┐      ┌──────────┐      ┌──────────┐          │ │    │ |
|  │  │  │  │Ring Buf 0│      │Ring Buf 1│      │Ring Buf 2│          │ │    │ |
|  │  │  │  │          │      │          │      │          │          │ │    │ |
|  │  │  │  │ Event    │      │ Event    │      │ Event    │          │ │    │ |
|  │  │  │  │ Event    │      │ Event    │      │ Event    │          │ │    │ |
|  │  │  │  │ Event    │      │ Event    │      │ Event    │          │ │    │ |
|  │  │  │  │ ...      │      │ ...      │      │ ...      │          │ │    │ |
|  │  │  │  └──────────┘      └──────────┘      └──────────┘          │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  Benefits:                                                  │ │    │ |
|  │  │  │  • No locks between CPUs                                    │ │    │ |
|  │  │  │  • No cache line bouncing                                   │ │    │ |
|  │  │  │  • Fixed memory, no allocation                              │ │    │ |
|  │  │  │  • Old events overwritten (not lost - just oldest)          │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  └────────────────────────────────────────────────────────────┘ │    │ |
|  │  │                                                                  │    │ |
|  │  └─────────────────────────────────────────────────────────────────┘    │ |
|  │                                                                          │ |
|  │  3. BINARY FORMAT                                                         │ |
|  │  ┌─────────────────────────────────────────────────────────────────┐    │ |
|  │  │                                                                  │    │ |
|  │  │  ┌────────────────────────────────────────────────────────────┐ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  Log style:                                                 │ │    │ |
|  │  │  │  sprintf("read %d bytes from fd %d", len, fd);              │ │    │ |
|  │  │  │  → String formatting: ~500 ns                               │ │    │ |
|  │  │  │  → Write 50 bytes                                           │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  Trace style:                                               │ │    │ |
|  │  │  │  struct { u64 ts; u32 len; u32 fd; } event;                 │ │    │ |
|  │  │  │  memcpy(buf, &event, sizeof(event));                        │ │    │ |
|  │  │  │  → Just copy: ~50 ns                                        │ │    │ |
|  │  │  │  → Write 16 bytes                                           │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  10x faster, 3x less data                                   │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  └────────────────────────────────────────────────────────────┘ │    │ |
|  │  │                                                                  │    │ |
|  │  └─────────────────────────────────────────────────────────────────┘    │ |
|  │                                                                          │ |
|  │  OVERHEAD SUMMARY                                                         │ |
|  │  ┌─────────────────────────────────────────────────────────────────┐    │ |
|  │  │                                                                  │    │ |
|  │  │  State                       Overhead                            │    │ |
|  │  │  ─────────────────────────────────────────────────────           │    │ |
|  │  │  Tracepoint disabled         ~0 cycles (NOP)                     │    │ |
|  │  │  Tracepoint enabled          ~100-300 ns per event               │    │ |
|  │  │  kprobe (dynamic)            ~500-1000 ns per probe              │    │ |
|  │  │  BPF program                 ~100-1000 ns depending on program   │    │ |
|  │  │  function_graph tracer       ~500 ns per function call           │    │ |
|  │  │                                                                  │    │ |
|  │  └─────────────────────────────────────────────────────────────────┘    │ |
|  │                                                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
+=============================================================================+
```

**中文说明：**

**复杂度：低开销**

**开销挑战**：
- 热路径：调度器（10K-100K/秒/CPU）、网络栈（1M+ 包/秒）、块 I/O（100K+ IOPS）
- 如果追踪给调度器增加 1 μs：100K/sec × 1 μs = 10% CPU 开销！

**Linux 开销优化技术**：

1. **静态分支（Jump Labels）**
   - 禁用时：编译为 NOP，~0 周期
   - 启用时：NOP 被修补为 JMP
   - 无运行时条件检查

2. **环形缓冲区（Per-CPU）**
   - 每 CPU 独立缓冲区
   - CPU 之间无锁、无缓存行弹跳
   - 固定内存，无分配
   - 旧事件被覆盖

3. **二进制格式**
   - 日志风格：sprintf 格式化 ~500 ns，写 50 字节
   - 追踪风格：memcpy 结构体 ~50 ns，写 16 字节
   - 快 10 倍，数据少 3 倍

**开销摘要**：
- Tracepoint 禁用：~0 周期
- Tracepoint 启用：~100-300 ns/事件
- kprobe：~500-1000 ns/探针
- BPF 程序：~100-1000 ns

---

## 4. 可观测性演进

```
OBSERVABILITY EVOLUTION
+=============================================================================+
|                                                                              |
|  TIMELINE                                                                    |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                                                                          │ |
|  │  1991: Linux 0.01                                                        │ |
|  │        • printk() only                                                   │ |
|  │        • dmesg for kernel messages                                       │ |
|  │                                                                          │ |
|  │  1999: LTT (Linux Trace Toolkit)                                         │ |
|  │        • First real tracing framework                                    │ |
|  │        • Static instrumentation                                          │ |
|  │                                                                          │ |
|  │  2004: Kprobes merged                                                    │ |
|  │        • Dynamic probes on any kernel function                           │ |
|  │        • No kernel rebuild needed                                        │ |
|  │                                                                          │ |
|  │  2008: Ftrace merged (2.6.27)                                            │ |
|  │        • Function tracer                                                 │ |
|  │        • Trace events                                                    │ |
|  │        • Ring buffer infrastructure                                      │ |
|  │                                                                          │ |
|  │  2009: Tracepoints merged (2.6.28)                                       │ |
|  │        • Static, stable trace points                                     │ |
|  │        • Defined API for subsystems                                      │ |
|  │                                                                          │ |
|  │  2009: Perf events merged (2.6.31)                                       │ |
|  │        • Hardware performance counters                                   │ |
|  │        • Sampling profiler                                               │ |
|  │        • User-space integration                                          │ |
|  │                                                                          │ |
|  │  2012: Uprobes merged (3.5)                                              │ |
|  │        • Dynamic probes in user-space                                    │ |
|  │                                                                          │ |
|  │  2014: eBPF begins (3.15+)                                               │ |
|  │        • Extended BPF for tracing                                        │ |
|  │        • Safe, verified programs                                         │ |
|  │                                                                          │ |
|  │  2016: BPF tracing matures (4.x)                                         │ |
|  │        • kprobes, uprobes via BPF                                        │ |
|  │        • Maps for aggregation                                            │ |
|  │        • bcc, bpftrace tools                                             │ |
|  │                                                                          │ |
|  │  2019: BPF CO-RE (5.x)                                                   │ |
|  │        • Compile Once, Run Everywhere                                    │ |
|  │        • Portable BPF programs                                           │ |
|  │                                                                          │ |
|  │  2022+: User Ring Buffer, BPF Arena                                      │ |
|  │         • High-performance user-space integration                        │ |
|  │         • Continuous BPF evolution                                       │ |
|  │                                                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
|  TRACING STACK TODAY                                                         |
|  ┌────────────────────────────────────────────────────────────────────────┐ |
|  │                                                                          │ |
|  │  ┌─────────────────────────────────────────────────────────────────┐    │ |
|  │  │                                                                  │    │ |
|  │  │  User-Space Tools                                                │    │ |
|  │  │  ┌────────────────────────────────────────────────────────────┐ │    │ |
|  │  │  │  bpftrace │ perf │ trace-cmd │ bcc │ strace │ ltrace       │ │    │ |
|  │  │  └─────────────────────────────┬──────────────────────────────┘ │    │ |
|  │  │                                │                                 │    │ |
|  │  │  ════════════════════════════════════════════════════════════   │    │ |
|  │  │                                │                                 │    │ |
|  │  │  Kernel Interfaces             ▼                                 │    │ |
|  │  │  ┌────────────────────────────────────────────────────────────┐ │    │ |
|  │  │  │  tracefs │ perf_event │ BPF syscall │ ptrace               │ │    │ |
|  │  │  └─────────────────────────────┬──────────────────────────────┘ │    │ |
|  │  │                                │                                 │    │ |
|  │  │  Kernel Infrastructure         ▼                                 │    │ |
|  │  │  ┌────────────────────────────────────────────────────────────┐ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐    │ │    │ |
|  │  │  │  │ Ftrace   │  │ Perf     │  │  BPF     │  │ Kprobes  │    │ │    │ |
|  │  │  │  │          │  │          │  │          │  │ Uprobes  │    │ │    │ |
|  │  │  │  └────┬─────┘  └────┬─────┘  └────┬─────┘  └────┬─────┘    │ │    │ |
|  │  │  │       │             │             │             │          │ │    │ |
|  │  │  │       └─────────────┴─────────────┴─────────────┘          │ │    │ |
|  │  │  │                          │                                  │ │    │ |
|  │  │  │                          ▼                                  │ │    │ |
|  │  │  │  ┌──────────────────────────────────────────────────────┐  │ │    │ |
|  │  │  │  │              Ring Buffer / Maps                       │  │ │    │ |
|  │  │  │  └──────────────────────────────────────────────────────┘  │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  │  ┌──────────────────────────────────────────────────────┐  │ │    │ |
|  │  │  │  │              Tracepoints (static hooks)               │  │ │    │ |
|  │  │  │  └──────────────────────────────────────────────────────┘  │ │    │ |
|  │  │  │                                                             │ │    │ |
|  │  │  └────────────────────────────────────────────────────────────┘ │    │ |
|  │  │                                                                  │    │ |
|  │  └─────────────────────────────────────────────────────────────────┘    │ |
|  │                                                                          │ |
|  └────────────────────────────────────────────────────────────────────────┘ |
|                                                                              |
+=============================================================================+
```

**中文说明：**

**可观测性演进**：

时间线：
- 1991：Linux 0.01 - 仅 printk()
- 2004：Kprobes - 任意内核函数动态探针
- 2008：Ftrace - 函数追踪器、追踪事件、环形缓冲区
- 2009：Tracepoints - 静态、稳定追踪点
- 2009：Perf events - 硬件性能计数器
- 2012：Uprobes - 用户空间动态探针
- 2014：eBPF 开始 - 安全、验证的程序
- 2016：BPF 追踪成熟 - bcc、bpftrace
- 2019：BPF CO-RE - 编译一次，随处运行

**今天的追踪栈**：

**用户空间工具**：bpftrace、perf、trace-cmd、bcc、strace

**内核接口**：tracefs、perf_event、BPF syscall、ptrace

**内核基础设施**：
- Ftrace、Perf、BPF、Kprobes/Uprobes
- 环形缓冲区 / Maps
- Tracepoints（静态钩子）
